{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielAdama/tutorials/blob/main/Causual_Lang_Model_development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNhD5F0eX7xO",
        "outputId": "b9f45527-e921-4ac1-842d-18df17447baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.161)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.28.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.26.129)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.129 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.29.129)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.129->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.129->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.129->boto3) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colab-env in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dotenv<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from colab-env) (0.21.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install sentence_transformers\n",
        "!pip install datasets\n",
        "!pip install boto3\n",
        "!pip install colab-env --upgrade\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"from accelerate.utils import write_basic_config; write_basic_config(mixed_precision='fp16')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkFic9fMH7vM",
        "outputId": "c7b690f7-f7d6-4e4a-c751-e914808a47d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-08 12:47:34.010601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exj_nsKhImI_",
        "outputId": "a82dd24b-9fdf-4d6f-ed0f-5c64b7ab61e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-08 12:47:42.883018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "Copy-and-paste the text below in your GitHub issue\n",
            "\n",
            "- `Accelerate` version: 0.18.0\n",
            "- Platform: Linux-5.10.147+-x86_64-with-glibc2.31\n",
            "- Python version: 3.10.11\n",
            "- Numpy version: 1.22.4\n",
            "- PyTorch version (GPU?): 2.0.0+cu118 (True)\n",
            "- `Accelerate` default config:\n",
            "\t- compute_environment: LOCAL_MACHINE\n",
            "\t- distributed_type: NO\n",
            "\t- mixed_precision: fp16\n",
            "\t- use_cpu: False\n",
            "\t- num_processes: 1\n",
            "\t- machine_rank: 0\n",
            "\t- num_machines: 1\n",
            "\t- rdzv_backend: static\n",
            "\t- same_network: False\n",
            "\t- main_training_function: main\n",
            "\t- downcast_bf16: False\n",
            "\t- tpu_use_cluster: False\n",
            "\t- tpu_use_sudo: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "V9uw6wjrhuM1",
        "outputId": "ff762fbe-b50f-4217-b897-001b495e0c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import colab_env\n",
        "colab_env.__version__\n",
        "# !more gdrive/My\\ Drive/vars.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGsMASx8h8Iq"
      },
      "outputs": [],
      "source": [
        "colab_env.envvar_handler.add_env(\"AWS_SECRET_ACCESS_KEY\", \"\", overwrite=False)\n",
        "colab_env.envvar_handler.add_env(\"AWS_ACCESS_KEY_ID\", \"\", overwrite=False)\n",
        "colab_env.envvar_handler.add_env(\"AWS_BUCKET_NAME\", \"\", overwrite=False)\n",
        "colab_env.envvar_handler.add_env(\"AWS_MODEL_BUCKET_NAME\", \"\", overwrite=False)\n",
        "\n",
        "# !more gdrive/My\\ Drive/vars.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQzylM0Z2_m7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from datasets import (Dataset, load_dataset, DatasetDict)\n",
        "import boto3\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    GPT2Tokenizer, \n",
        "    GPT2LMHeadModel, \n",
        "    AutoConfig, \n",
        "    DataCollatorForLanguageModeling, \n",
        "    Trainer, \n",
        "    TrainingArguments\n",
        ")\n",
        "import json\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
        "    aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "    )"
      ],
      "metadata": {
        "id": "-tjUVnRqGJD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jsonl():\n",
        "  \n",
        "  ds_valid = []\n",
        "  ds_train = []\n",
        "\n",
        "  count = 0\n",
        "  remoteObjs = s3.list_objects_v2(Bucket=os.getenv(\"AWS_BUCKET_NAME\"))\n",
        "  for obj in remoteObjs['Contents']:\n",
        "    count += 1\n",
        "    path = obj['Key']\n",
        "    if count == 1:\n",
        "      trainobj = s3.get_object(Bucket=os.getenv(\"AWS_BUCKET_NAME\"), Key=path)\n",
        "      body = trainobj['Body'].read().decode('utf-8')\n",
        "      lines = body.split('\\n')\n",
        "      for line in lines:\n",
        "          if line.strip() != '':\n",
        "              ds_train.append(json.loads(line))\n",
        "    else:\n",
        "      validobj = s3.get_object(Bucket=os.getenv(\"AWS_BUCKET_NAME\"), Key=path)\n",
        "      body = validobj['Body'].read().decode('utf-8')\n",
        "      lines = body.split('\\n')\n",
        "      for line in lines:\n",
        "          if line.strip() != '':\n",
        "              ds_valid.append(json.loads(line))\n",
        "\n",
        "  return ds_train, ds_valid"
      ],
      "metadata": {
        "id": "oBXQTOPxG40n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_valid = load_jsonl()"
      ],
      "metadata": {
        "id": "-BQEr8M0G43D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwrKZriz9YNl"
      },
      "source": [
        "**The script below is to load data in chucks locally!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgGNp-JO9TDf"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "# from tqdm import tqdm\n",
        "# import json\n",
        "\n",
        "\n",
        "# train = 'codeparrot-ds-train.jsonl'\n",
        "# sub = 'codeparrot-ds-sub-train.jsonl'\n",
        "# data = r'/home/chuby/Desktop/programming/NLP/gpt-2-train/datasets'\n",
        "\n",
        "# # with open(os.path.join(data,'codeparrot-ds-valid.jsonl'), 'r') as docs:\n",
        "#     # for line in docs:\n",
        "#     #     test_ds.append(json.loads(line))\n",
        "\n",
        "# # print(test_dict)\n",
        "\n",
        "# num_lines = sum(1 for line in open(os.path.join(data,train)))\n",
        "# print(f'Num. of samples in train dataset: {num_lines:,}')\n",
        "\n",
        "# # with open(data) as infile:\n",
        "# #   o = json.load(infile)\n",
        "# #   chunkSize = 1000\n",
        "# #   for i in xrange(0, len(o), chunkSize):\n",
        "# #     with open('file_' + str(i//chunkSize) + '.jsonl', 'wb') as outfile:\n",
        "# #       json.dump(o[i:i+chunkSize], outfile)\n",
        "\n",
        "\n",
        "# chunksize = 1000\n",
        "# chunks = pd.read_json(os.path.join(data,train), lines=True, chunksize=chunksize)\n",
        "# sub_data = []\n",
        "# for chunk in tqdm(chunks):\n",
        "#     sub_data.append(chunk)\n",
        "#     if len(sub_data) == 3:\n",
        "#        break\n",
        "\n",
        "# test_ds = []\n",
        "# interactions = pd.concat(sub_data, ignore_index=True, sort=True)\n",
        "# interactions = interactions.reindex(columns=['repo_name','path', 'copies', 'size', 'content', 'license'])\n",
        "# print(interactions.head())\n",
        "# print(interactions.shape)\n",
        "# interactions.to_json(os.path.join(data,sub), orient='records', lines=True)\n",
        "# with open(os.path.join(data,sub), 'r') as docs:\n",
        "#     for line in docs:\n",
        "#         test_ds.append(json.loads(line))\n",
        "\n",
        "# print(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_DUfZK173Tm"
      },
      "outputs": [],
      "source": [
        "def any_keyword_in_string(string: str, keywords):\n",
        "  return any(keyword in string for keyword in keywords)\n",
        "\n",
        "def filter_streaming_dataset(dataset, filters):\n",
        "  filter_dict = defaultdict(list)\n",
        "  total = 0\n",
        "  for sample in tqdm(iter(dataset)):\n",
        "    total += 1\n",
        "    if any_keyword_in_string(sample[\"content\"], filters):\n",
        "      for k, v in sample.items():\n",
        "        filter_dict[k].append(v)\n",
        "        print(f\"{len(filter_dict['content'])/total:.2%} of data after filtering.\")\n",
        "  return Dataset.from_dict(filter_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0PTLqcTyOsE",
        "outputId": "6ee2ea5f-5007-4fc7-c6d2-788eff3dcbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False True\n"
          ]
        }
      ],
      "source": [
        "os.getenv(\"AWS_SECRET_ACCESS_KEY\")filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
        "split = \"train\"  # \"valid\"\n",
        "\n",
        "example_1 = \"import numpy as np\"\n",
        "example_2 = \"import pandas as pd\"\n",
        "\n",
        "print(any_keyword_in_string(\"k\", \"keywords\"))\n",
        "\n",
        "print(\n",
        "    any_keyword_in_string(example_1, filters), any_keyword_in_string(example_2, filters)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8_FyQXzcewf"
      },
      "source": [
        "The cell below will take a long time to execute, so we will skip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK3UyN606GYO"
      },
      "outputs": [],
      "source": [
        "# data = load_dataset(f\"transformersbook/codeparrot-{split}\", split=split, streaming=True)\n",
        "# filtered_data = filter_streaming_dataset(data, filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt8WUI-4sigB"
      },
      "outputs": [],
      "source": [
        "# ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
        "# ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3eMHienoyqh"
      },
      "outputs": [],
      "source": [
        "# ds_valid = []\n",
        "# ds_train = []\n",
        "\n",
        "# with open(os.path.join('huggingface-course','codeparrot-ds-valid.jsonl'), 'r') as docs:\n",
        "#       for line in docs:\n",
        "#         ds_valid.append(json.loads(line))\n",
        "\n",
        "# with open(os.path.join('huggingface-course','codeparrot-ds-sub-train.jsonl'), 'r') as docs:\n",
        "#       for line in docs:\n",
        "#         ds_train.append(json.loads(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TsxjpH6ykWT",
        "outputId": "8dcb7320-6d80-4182-acc5-3859d79a69de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'repo_name': 'ratnania/pigasus',\n",
              " 'path': 'doc/manual/include/demo/test_neumann_quartcircle.py',\n",
              " 'copies': '1',\n",
              " 'size': '2730',\n",
              " 'content': '#! /usr/bin/python\\n\\n# ...\\ntry:\\n    from matplotlib import pyplot as plt\\n    PLOT=True\\nexcept ImportError:\\n    PLOT=False\\n# ...\\nimport numpy                as np\\nfrom pigasus.gallery.poisson import *\\nimport sys\\nimport inspect\\nfilename = inspect.getfile(inspect.currentframe()) # script filename (usually with path)\\n\\n# ...\\nsin = np.sin ; cos = np.cos ; pi = np.pi ; exp = np.exp\\n# ...\\n\\n#-----------------------------------\\ntry:\\n    nx = int(sys.argv[1])\\nexcept:\\n    nx = 31\\n\\ntry:\\n    ny = int(sys.argv[2])\\nexcept:\\n    ny = 31\\n\\ntry:\\n    px = int(sys.argv[3])\\nexcept:\\n    px = 2\\n\\ntry:\\n    py = int(sys.argv[4])\\nexcept:\\n    py = 2\\n\\nfrom igakit.cad_geometry import quart_circle as domain\\ngeo = domain(n=[nx,ny],p=[px,py])\\n#-----------------------------------\\n\\n# ...\\n# exact solution\\n# ...\\nR = 1.\\nr = 0.5\\nc = 1. # for neumann\\n#c = pi / (R**2-r**2) # for all dirichlet bc\\nu = lambda x,y : [ x * y * sin ( c * (R**2 - x**2 - y**2 )) ]\\n# ...\\n\\n# ...\\n# rhs\\n# ...\\nf = lambda x,y : [4*c**2*x**3*y*sin(c*(R**2 - x**2 - y**2)) \\\\\\n                  + 4*c**2*x*y**3*sin(c*(R**2 - x**2 - y**2)) \\\\\\n                  + 12*c*x*y*cos(c*(R**2 - x**2 - y**2)) ]\\n# ...\\n\\n# ...\\n# values of gradu.n at the boundary\\n# ...\\ngradu   = lambda x,y : [-2*c*x**2*y*cos(c*(R**2 - x**2 - y**2)) + y*sin(c*(R**2\\n                                                                           -\\n                                                                           x**2\\n                                                                           -\\n                                                                           y**2)) \\\\\\n                       ,-2*c*x*y**2*cos(c*(R**2 - x**2 - y**2)) + x*sin(c*(R**2 - x**2 - y**2)) ]\\n\\ndef func_g (x,y) :\\n    du  = gradu (x, y)\\n    return [ du[0] , du[1] ]\\n# ...\\n\\n# ...\\n# values of u at the boundary\\n# ...\\n\\nbc_neumann={}\\n\\nbc_neumann [0,0] = func_g\\nDirichlet = [[1,2,3]]\\n\\n#AllDirichlet = True\\n# ...\\n\\n# ...\\ntry:\\n    bc_dirichlet\\nexcept NameError:\\n    bc_dirichlet = None\\nelse:\\n    pass\\n\\ntry:\\n    bc_neumann\\nexcept NameError:\\n    bc_neumann = None\\nelse:\\n    pass\\n\\ntry:\\n    AllDirichlet\\nexcept NameError:\\n    AllDirichlet = None\\nelse:\\n    pass\\n\\ntry:\\n    Dirichlet\\nexcept NameError:\\n    Dirichlet = None\\nelse:\\n    pass\\n\\ntry:\\n    Metric\\nexcept NameError:\\n    Metric = None\\nelse:\\n    pass\\n# ...\\n\\n# ...\\nPDE = poisson(geometry=geo, bc_dirichlet=bc_dirichlet, bc_neumann=bc_neumann,\\n              AllDirichlet=AllDirichlet, Dirichlet=Dirichlet,metric=Metric)\\n# ...\\n\\n# ...\\nPDE.assembly(f=f)\\nPDE.solve()\\n# ...\\n\\n# ...\\nnormU = PDE.norm(exact=u)\\nprint \"norm U   = \", normU\\n# ...\\n\\n# ...\\nif PLOT:\\n    PDE.plot()  ; plt.colorbar(); plt.title(\\'$u_h$\\')\\n    plt.savefig(filename.split(\\'.py\\')[0]+\\'.png\\', format=\\'png\\')\\n    plt.clf()\\n# ...\\n\\nPDE.free()\\n',\n",
              " 'license': 'mit'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ds_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTEz--gpw5HF",
        "outputId": "ca82f8fe-88ad-45fd-aeed-c5a0e16f67c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'repo_name': 'kmike/scikit-learn',\n",
              " 'path': 'sklearn/utils/__init__.py',\n",
              " 'copies': 3,\n",
              " 'size': 10094,\n",
              " 'content': '\"\"\"\\nThe :mod:`sklearn.utils` module includes various utilites.\\n\"\"\"\\n\\nfrom collections import Sequence\\n\\nimport numpy as np\\nfrom scipy.sparse import issparse\\nimport warnings\\n\\nfrom .murmurhash import murmurhash3_32\\nfrom .validation import (as_float_array, check_arrays, safe_asarray,\\n                         assert_all_finite, array2d, atleast2d_or_csc,\\n                         atleast2d_or_csr, warn_if_not_float,\\n                         check_random_state)\\nfrom .class_weight import compute_class_weight\\n\\n__all__ = [\"murmurhash3_32\", \"as_float_array\", \"check_arrays\", \"safe_asarray\",\\n           \"assert_all_finite\", \"array2d\", \"atleast2d_or_csc\",\\n           \"atleast2d_or_csr\", \"warn_if_not_float\", \"check_random_state\",\\n           \"compute_class_weight\"]\\n\\n# Make sure that DeprecationWarning get printed\\nwarnings.simplefilter(\"always\", DeprecationWarning)\\n\\n\\nclass deprecated(object):\\n    \"\"\"Decorator to mark a function or class as deprecated.\\n\\n    Issue a warning when the function is called/the class is instantiated and\\n    adds a warning to the docstring.\\n\\n    The optional extra argument will be appended to the deprecation message\\n    and the docstring. Note: to use this with the default value for extra, put\\n    in an empty of parentheses:\\n\\n    >>> from sklearn.utils import deprecated\\n    >>> deprecated() # doctest: +ELLIPSIS\\n    <sklearn.utils.deprecated object at ...>\\n\\n    >>> @deprecated()\\n    ... def some_function(): pass\\n    \"\"\"\\n\\n    # Adapted from http://wiki.python.org/moin/PythonDecoratorLibrary,\\n    # but with many changes.\\n\\n    def __init__(self, extra=\\'\\'):\\n        \"\"\"\\n        Parameters\\n        ----------\\n        extra: string\\n          to be added to the deprecation messages\\n\\n        \"\"\"\\n        self.extra = extra\\n\\n    def __call__(self, obj):\\n        if isinstance(obj, type):\\n            return self._decorate_class(obj)\\n        else:\\n            return self._decorate_fun(obj)\\n\\n    def _decorate_class(self, cls):\\n        msg = \"Class %s is deprecated\" % cls.__name__\\n        if self.extra:\\n            msg += \"; %s\" % self.extra\\n\\n        # FIXME: we should probably reset __new__ for full generality\\n        init = cls.__init__\\n\\n        def wrapped(*args, **kwargs):\\n            warnings.warn(msg, category=DeprecationWarning)\\n            return init(*args, **kwargs)\\n        cls.__init__ = wrapped\\n\\n        wrapped.__name__ = \\'__init__\\'\\n        wrapped.__doc__ = self._update_doc(init.__doc__)\\n        wrapped.deprecated_original = init\\n\\n        return cls\\n\\n    def _decorate_fun(self, fun):\\n        \"\"\"Decorate function fun\"\"\"\\n\\n        msg = \"Function %s is deprecated\" % fun.__name__\\n        if self.extra:\\n            msg += \"; %s\" % self.extra\\n\\n        def wrapped(*args, **kwargs):\\n            warnings.warn(msg, category=DeprecationWarning)\\n            return fun(*args, **kwargs)\\n\\n        wrapped.__name__ = fun.__name__\\n        wrapped.__dict__ = fun.__dict__\\n        wrapped.__doc__ = self._update_doc(fun.__doc__)\\n\\n        return wrapped\\n\\n    def _update_doc(self, olddoc):\\n        newdoc = \"DEPRECATED\"\\n        if self.extra:\\n            newdoc = \"%s: %s\" % (newdoc, self.extra)\\n        if olddoc:\\n            newdoc = \"%s\\\\n\\\\n%s\" % (newdoc, olddoc)\\n        return newdoc\\n\\n\\ndef safe_mask(X, mask):\\n    \"\"\"Return a mask which is safe to use on X.\\n\\n    Parameters\\n    ----------\\n    X : {array-like, sparse matrix}\\n        Data on which to apply mask.\\n\\n    mask: array\\n        Mask to be used on X.\\n\\n    Returns\\n    -------\\n        mask\\n    \"\"\"\\n    mask = np.asanyarray(mask)\\n    if np.issubdtype(mask.dtype, np.int):\\n        return mask\\n\\n    if hasattr(X, \"toarray\"):\\n        ind = np.arange(mask.shape[0])\\n        mask = ind[mask]\\n    return mask\\n\\n\\ndef resample(*arrays, **options):\\n    \"\"\"Resample arrays or sparse matrices in a consistent way\\n\\n    The default strategy implements one step of the bootstrapping\\n    procedure.\\n\\n    Parameters\\n    ----------\\n    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\\n\\n    replace : boolean, True by default\\n        Implements resampling with replacement. If False, this will implement\\n        (sliced) random permutations.\\n\\n    n_samples : int, None by default\\n        Number of samples to generate. If left to None this is\\n        automatically set to the first dimension of the arrays.\\n\\n    random_state : int or RandomState instance\\n        Control the shuffling for reproducible behavior.\\n\\n    Returns\\n    -------\\n    Sequence of resampled views of the collections. The original arrays are\\n    not impacted.\\n\\n    Examples\\n    --------\\n    It is possible to mix sparse and dense arrays in the same run::\\n\\n      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\\n      >>> y = np.array([0, 1, 2])\\n\\n      >>> from scipy.sparse import coo_matrix\\n      >>> X_sparse = coo_matrix(X)\\n\\n      >>> from sklearn.utils import resample\\n      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\\n      >>> X\\n      array([[ 1.,  0.],\\n             [ 2.,  1.],\\n             [ 1.,  0.]])\\n\\n      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\\n      <3x2 sparse matrix of type \\'<... \\'numpy.float64\\'>\\'\\n          with 4 stored elements in Compressed Sparse Row format>\\n\\n      >>> X_sparse.toarray()\\n      array([[ 1.,  0.],\\n             [ 2.,  1.],\\n             [ 1.,  0.]])\\n\\n      >>> y\\n      array([0, 1, 0])\\n\\n      >>> resample(y, n_samples=2, random_state=0)\\n      array([0, 1])\\n\\n\\n    See also\\n    --------\\n    :class:`sklearn.cross_validation.Bootstrap`\\n    :func:`sklearn.utils.shuffle`\\n    \"\"\"\\n    random_state = check_random_state(options.pop(\\'random_state\\', None))\\n    replace = options.pop(\\'replace\\', True)\\n    max_n_samples = options.pop(\\'n_samples\\', None)\\n    if options:\\n        raise ValueError(\"Unexpected kw arguments: %r\" % options.keys())\\n\\n    if len(arrays) == 0:\\n        return None\\n\\n    first = arrays[0]\\n    n_samples = first.shape[0] if hasattr(first, \\'shape\\') else len(first)\\n\\n    if max_n_samples is None:\\n        max_n_samples = n_samples\\n\\n    if max_n_samples > n_samples:\\n        raise ValueError(\"Cannot sample %d out of arrays with dim %d\" % (\\n            max_n_samples, n_samples))\\n\\n    arrays = check_arrays(*arrays, sparse_format=\\'csr\\')\\n\\n    if replace:\\n        indices = random_state.randint(0, n_samples, size=(max_n_samples,))\\n    else:\\n        indices = np.arange(n_samples)\\n        random_state.shuffle(indices)\\n        indices = indices[:max_n_samples]\\n\\n    resampled_arrays = []\\n\\n    for array in arrays:\\n        array = array[indices]\\n        resampled_arrays.append(array)\\n\\n    if len(resampled_arrays) == 1:\\n        # syntactic sugar for the unit argument case\\n        return resampled_arrays[0]\\n    else:\\n        return resampled_arrays\\n\\n\\ndef shuffle(*arrays, **options):\\n    \"\"\"Shuffle arrays or sparse matrices in a consistent way\\n\\n    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\\n    random permutations of the collections.\\n\\n    Parameters\\n    ----------\\n    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\\n\\n    random_state : int or RandomState instance\\n        Control the shuffling for reproducible behavior.\\n\\n    n_samples : int, None by default\\n        Number of samples to generate. If left to None this is\\n        automatically set to the first dimension of the arrays.\\n\\n    Returns\\n    -------\\n    Sequence of shuffled views of the collections. The original arrays are\\n    not impacted.\\n\\n    Examples\\n    --------\\n    It is possible to mix sparse and dense arrays in the same run::\\n\\n      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\\n      >>> y = np.array([0, 1, 2])\\n\\n      >>> from scipy.sparse import coo_matrix\\n      >>> X_sparse = coo_matrix(X)\\n\\n      >>> from sklearn.utils import shuffle\\n      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\\n      >>> X\\n      array([[ 0.,  0.],\\n             [ 2.,  1.],\\n             [ 1.,  0.]])\\n\\n      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\\n      <3x2 sparse matrix of type \\'<... \\'numpy.float64\\'>\\'\\n          with 3 stored elements in Compressed Sparse Row format>\\n\\n      >>> X_sparse.toarray()\\n      array([[ 0.,  0.],\\n             [ 2.,  1.],\\n             [ 1.,  0.]])\\n\\n      >>> y\\n      array([2, 1, 0])\\n\\n      >>> shuffle(y, n_samples=2, random_state=0)\\n      array([0, 1])\\n\\n    See also\\n    --------\\n    :func:`sklearn.utils.resample`\\n    \"\"\"\\n    options[\\'replace\\'] = False\\n    return resample(*arrays, **options)\\n\\n\\ndef safe_sqr(X, copy=True):\\n    \"\"\"Element wise squaring of array-likes and sparse matrices.\\n\\n    Parameters\\n    ----------\\n    X : array like, matrix, sparse matrix\\n\\n    Returns\\n    -------\\n    X ** 2 : element wise square\\n    \"\"\"\\n    X = safe_asarray(X)\\n    if issparse(X):\\n        if copy:\\n            X = X.copy()\\n        X.data **= 2\\n    else:\\n        if copy:\\n            X = X ** 2\\n        else:\\n            X **= 2\\n    return X\\n\\n\\ndef gen_even_slices(n, n_packs):\\n    \"\"\"Generator to create n_packs slices going up to n.\\n\\n    Examples\\n    --------\\n    >>> from sklearn.utils import gen_even_slices\\n    >>> list(gen_even_slices(10, 1))\\n    [slice(0, 10, None)]\\n    >>> list(gen_even_slices(10, 10))                     #doctest: +ELLIPSIS\\n    [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\\n    >>> list(gen_even_slices(10, 5))                      #doctest: +ELLIPSIS\\n    [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\\n    >>> list(gen_even_slices(10, 3))\\n    [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]\\n    \"\"\"\\n    start = 0\\n    for pack_num in range(n_packs):\\n        this_n = n // n_packs\\n        if pack_num < n % n_packs:\\n            this_n += 1\\n        if this_n > 0:\\n            end = start + this_n\\n            yield slice(start, end, None)\\n            start = end\\n\\n\\ndef tosequence(x):\\n    \"\"\"Cast iterable x to a Sequence, avoiding a copy if possible.\"\"\"\\n    if isinstance(x, np.ndarray):\\n        return np.asarray(x)\\n    elif isinstance(x, Sequence):\\n        return x\\n    else:\\n        return list(x)\\n\\n\\nclass ConvergenceWarning(Warning):\\n    \"Custom warning to capture convergence problems\"\\n',\n",
              " 'license': 'bsd-3-clause'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ds_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdppBy-D_Qfp",
        "outputId": "d0777a9e-ab6b-4116-acb7-5abae353881f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
            "    num_rows: 20000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
            "    num_rows: 3322\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "valid_dict = {k: [d[k] for d in ds_valid] for k in ds_valid[0]}\n",
        "train_dict = {k: [d[k] for d in ds_train] for k in ds_train[0]}\n",
        "valid_set = Dataset.from_dict(valid_dict)\n",
        "train_set = Dataset.from_dict(train_dict)\n",
        "\n",
        "print(train_set)\n",
        "print(valid_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrYQBlESyOeB",
        "outputId": "b6c71542-a6f8-4c03-e0f2-2649530e23cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
              "        num_rows: 3322\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "raw_dataset = DatasetDict(\n",
        "    {\n",
        "        \"train\": train_set.shuffle(), #.select(range(1000)),\n",
        "        \"valid\": valid_set.shuffle() #.select(range(500))\n",
        "    }\n",
        ")\n",
        "\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMuvFCufyOYP",
        "outputId": "659331cb-4c87-4e55-cb64-7a797b479d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPO_NAME: fengzhyuan/scikit-learn\n",
            "PATH: sklearn/ensemble/tests/test_partial_dependence.py\n",
            "COPIES: 365\n",
            "SIZE: 6996\n",
            "CONTENT: \"\"\"\n",
            "Testing for the partial dependence module.\n",
            "\"\"\"\n",
            "\n",
            "import numpy as np\n",
            "from numpy.testing import assert_array_equal\n",
            "\n",
            "from sklearn.utils.testing import assert_raises\n",
            "from sklearn.utils.testing import if_matplotlib\n",
            "from sklearn.ensemble.partial_dependence import partial_dependence\n",
            "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
            "from sklearn.ensemble import GradientBoostingClassifier\n",
            "from sklearn.ensemble import GradientBoostingRegressor\n",
            "from sklearn import datasets\n",
            "\n",
            "\n",
            "# toy sample\n",
            "X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]\n",
            "y = [-1, -1, -1, 1, 1, 1]\n",
            "T = [[-1, -1], [2, 2], [3, 2]]\n",
            "true_result = [-1, 1, 1]\n",
            "\n",
            "# also load the boston dataset\n",
            "boston = datasets.load_boston()\n",
            "\n",
            "# also load the iris dataset\n",
            "iris = datasets.load_iris()\n",
            "\n",
            "\n",
            "def test_partial_dependence_classifier():\n",
            "    # Test partial dependence for classifier\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "    clf.fit(X, y)\n",
            "\n",
            "    pdp, axes = partial_dependence(clf, [0], X=X, grid_resolution=5)\n",
            "\n",
            "    # only 4 grid points instead of 5 because only 4 unique X[:,0] vals\n",
            "    assert pdp.shape == (1, 4)\n",
            "    assert axes[0].shape[0] == 4\n",
            "\n",
            "    # now with our own grid\n",
            "    X_ = np.asarray(X)\n",
            "    grid = np.unique(X_[:, 0])\n",
            "    pdp_2, axes = partial_dependence(clf, [0], grid=grid)\n",
            "\n",
            "    assert axes is None\n",
            "    assert_array_equal(pdp, pdp_2)\n",
            "\n",
            "\n",
            "def test_partial_dependence_multiclass():\n",
            "    # Test partial dependence for multi-class classifier\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "    clf.fit(iris.data, iris.target)\n",
            "\n",
            "    grid_resolution = 25\n",
            "    n_classes = clf.n_classes_\n",
            "    pdp, axes = partial_dependence(\n",
            "        clf, [0], X=iris.data, grid_resolution=grid_resolution)\n",
            "\n",
            "    assert pdp.shape == (n_classes, grid_resolution)\n",
            "    assert len(axes) == 1\n",
            "    assert axes[0].shape[0] == grid_resolution\n",
            "\n",
            "\n",
            "def test_partial_dependence_regressor():\n",
            "    # Test partial dependence for regressor\n",
            "    clf = GradientBoostingRegressor(n_estimators=10, random_state=1)\n",
            "    clf.fit(boston.data, boston.target)\n",
            "\n",
            "    grid_resolution = 25\n",
            "    pdp, axes = partial_dependence(\n",
            "        clf, [0], X=boston.data, grid_resolution=grid_resolution)\n",
            "\n",
            "    assert pdp.shape == (1, grid_resolution)\n",
            "    assert axes[0].shape[0] == grid_resolution\n",
            "\n",
            "\n",
            "def test_partial_dependecy_input():\n",
            "    # Test input validation of partial dependence.\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "    clf.fit(X, y)\n",
            "\n",
            "    assert_raises(ValueError, partial_dependence,\n",
            "                  clf, [0], grid=None, X=None)\n",
            "\n",
            "    assert_raises(ValueError, partial_dependence,\n",
            "                  clf, [0], grid=[0, 1], X=X)\n",
            "\n",
            "    # first argument must be an instance of BaseGradientBoosting\n",
            "    assert_raises(ValueError, partial_dependence,\n",
            "                  {}, [0], X=X)\n",
            "\n",
            "    # Gradient boosting estimator must be fit\n",
            "    assert_raises(ValueError, partial_dependence,\n",
            "                  GradientBoostingClassifier(), [0], X=X)\n",
            "\n",
            "    assert_raises(ValueError, partial_dependence, clf, [-1], X=X)\n",
            "\n",
            "    assert_raises(ValueError, partial_dependence, clf, [100], X=X)\n",
            "\n",
            "    # wrong ndim for grid\n",
            "    grid = np.random.rand(10, 2, 1)\n",
            "    assert_raises(ValueError, partial_dependence, clf, [0], grid=grid)\n",
            "\n",
            "\n",
            "@if_matplotlib\n",
            "def test_plot_partial_dependence():\n",
            "    # Test partial dependence plot function.\n",
            "    clf = GradientBoostingRegressor(n_estimators=10, random_state=1)\n",
            "    clf.fit(boston.data, boston.target)\n",
            "\n",
            "    grid_resolution = 25\n",
            "    fig, axs = plot_partial_dependence(clf, boston.data, [0, 1, (0, 1)],\n",
            "                                       grid_resolution=grid_resolution,\n",
            "                                       feature_names=boston.feature_names)\n",
            "    assert len(axs) == 3\n",
            "    assert all(ax.has_data for ax in axs)\n",
            "\n",
            "    # check with str features and array feature names\n",
            "    fig, axs = plot_partial_dependence(clf, boston.data, ['CRIM', 'ZN',\n",
            "                                                          ('CRIM', 'ZN')],\n",
            "                                       grid_resolution=grid_resolution,\n",
            "                                       feature_names=boston.feature_names)\n",
            "\n",
            "    assert len(axs) == 3\n",
            "    assert all(ax.has_data for ax in axs)\n",
            "\n",
            "    # check with list feature_names\n",
            "    feature_names = boston.feature_names.tolist()\n",
            "    fig, axs = plot_partial_dependence(clf, boston.data, ['CRIM', 'ZN',\n",
            "                                                          ('CRIM', 'ZN')],\n",
            "                                       grid_resolution=grid_resolution,\n",
            "                                       feature_names=feature_names)\n",
            "    assert len(axs) == 3\n",
            "    assert all(ax.has_data for ax in axs)\n",
            "\n",
            "\n",
            "@if_matplotlib\n",
            "def test_plot_partial_dependence_input():\n",
            "    # Test partial dependence plot function input checks.\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "\n",
            "    # not fitted yet\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, X, [0])\n",
            "\n",
            "    clf.fit(X, y)\n",
            "\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, np.array(X)[:, :0], [0])\n",
            "\n",
            "    # first argument must be an instance of BaseGradientBoosting\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  {}, X, [0])\n",
            "\n",
            "    # must be larger than -1\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, X, [-1])\n",
            "\n",
            "    # too large feature value\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, X, [100])\n",
            "\n",
            "    # str feature but no feature_names\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, X, ['foobar'])\n",
            "\n",
            "    # not valid features value\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, X, [{'foo': 'bar'}])\n",
            "\n",
            "\n",
            "@if_matplotlib\n",
            "def test_plot_partial_dependence_multiclass():\n",
            "    # Test partial dependence plot function on multi-class input.\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "    clf.fit(iris.data, iris.target)\n",
            "\n",
            "    grid_resolution = 25\n",
            "    fig, axs = plot_partial_dependence(clf, iris.data, [0, 1],\n",
            "                                       label=0,\n",
            "                                       grid_resolution=grid_resolution)\n",
            "    assert len(axs) == 2\n",
            "    assert all(ax.has_data for ax in axs)\n",
            "\n",
            "    # now with symbol labels\n",
            "    target = iris.target_names[iris.target]\n",
            "    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n",
            "    clf.fit(iris.data, target)\n",
            "\n",
            "    grid_resolution = 25\n",
            "    fig, axs = plot_partial_dependence(clf, iris.data, [0, 1],\n",
            "                                       label='setosa',\n",
            "                                       grid_resolution=grid_resolution)\n",
            "    assert len(axs) == 2\n",
            "    assert all(ax.has_data for ax in axs)\n",
            "\n",
            "    # label not in gbrt.classes_\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, iris.data, [0, 1], label='foobar',\n",
            "                  grid_resolution=grid_resolution)\n",
            "\n",
            "    # label not provided\n",
            "    assert_raises(ValueError, plot_partial_dependence,\n",
            "                  clf, iris.data, [0, 1],\n",
            "                  grid_resolution=grid_resolution)\n",
            "\n",
            "LICENSE: bsd-3-clause\n"
          ]
        }
      ],
      "source": [
        "for key in raw_dataset[\"train\"][0]:\n",
        "  # check the data type of the value\n",
        "  value = raw_dataset['train'][0][key]\n",
        "  if isinstance(value, int):\n",
        "      # convert to a list or numpy array\n",
        "      value = str(value)\n",
        "      # or: value = np.array([value])\n",
        "  print(f\"{key.upper()}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlc0YTtZIFLq"
      },
      "source": [
        "# Encode Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE2nsc89yOVm"
      },
      "outputs": [],
      "source": [
        "# CHECKPOINT = 'gpt2'\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "CHECKPOINT = 'huggingface-course/code-search-net-tokenizer'\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr9RCMgeyORT"
      },
      "outputs": [],
      "source": [
        "# tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o575GpAZKbGj",
        "outputId": "92b6145a-8714-4fa7-8fef-911058b7654d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [25027, 300, 2827, 455, 31, 9772, 455, 300, 523, 19579, 336, 6204, 15655, 14], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenizer(\"What is your name?\", \"My name is Daniel Adama.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSFmpLvN_wS"
      },
      "source": [
        "Instead, well use the return_overflowing_tokens option to tokenize the whole input and split it into several chunks, as we did in Chapter 6. Well also use the return_length option to return the length of each created chunk automatically. Often the last chunk will be smaller than the context size, and well get rid of these pieces to avoid padding issues; we dont really need them as we have plenty of data anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyE4SU95KbMx",
        "outputId": "4b2c4080-1389-40b9-ed9d-e9d3f0cfc1ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs length: 89\n",
            "Input chunk lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 52, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26]\n",
            "Chunk mapping: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "context_length = 128\n",
        "\n",
        "outputs = tokenizer(\n",
        "    raw_dataset[\"train\"][:2][\"content\"],\n",
        "    truncation=True,\n",
        "    max_length=context_length,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_length=True,\n",
        ")\n",
        "\n",
        "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
        "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
        "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knr2bhugOqQa"
      },
      "source": [
        "We can see that we get 27 segments in total from those two examples. Looking at the chunk lengths, we can see that the chunks at the ends of both documents have less than 128 tokens (45 and 69, respectively). These represent just a small fraction of the total chunks that we have, so we can safely throw them away. With the *overflow_to_sample_mapping* field, we can also reconstruct which chunks belonged to which input samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195,
          "referenced_widgets": [
            "0a0ec05abce5481db9803fe516232985",
            "7f07c9a2314e4b51a773e4c2e25daa1a",
            "580ad9c52dc24f7eab779f40517cde58",
            "7a7eb40e6c874fde810540ce36b7d7fa",
            "0c6726f8fd824c2880ac30f2b28a3d1e",
            "b72d3567a0a3427788e47182eb57a75e",
            "04b5345e280b476d9417916044c86350",
            "fd98bb43c00e4c949faa17b8926e9090",
            "566526c82d224c65bcb74c7e935855d1",
            "b32892818a224901a0cb2b3d23e5e34d",
            "be64231095ce4439be5c8bb91b89773a",
            "3163246497954064a20a04511f5e99bb",
            "68e0ee91ccf142348299c3bacc482f9d",
            "713c9699ea3d47bd9f5061850dd4fdf7",
            "8c38e53a1ec94e8ca1bdba3e413ca52a",
            "75ed77403e13471cb6874cc2ec5fbd8d",
            "70c5078b93454d7baacc1d83007a949f",
            "28ed4e71627341cf8c8ee4ff427ce5b6",
            "a22738db48dd42b39fc28a1c7b55e3c0",
            "899328f2c65b450088bedd770a43db05",
            "c494cef61515495db5967e1e12dca9f3",
            "59ea99e5e6774511b209a2a73099b92c"
          ]
        },
        "id": "Y3fAa1YhKbPX",
        "outputId": "4f5ac5f7-e623-4dd2-afd4-ebbd8d71f75f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a0ec05abce5481db9803fe516232985"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3322 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3163246497954064a20a04511f5e99bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids'],\n",
              "        num_rows: 557217\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['input_ids'],\n",
              "        num_rows: 93164\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def tokenize(element):\n",
        "    outputs = tokenizer(\n",
        "        element[\"content\"],\n",
        "        truncation=True,\n",
        "        max_length=context_length,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_length=True,\n",
        "    )\n",
        "    input_batch = []\n",
        "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
        "        if length == context_length:\n",
        "            input_batch.append(input_ids)\n",
        "    return {\"input_ids\": input_batch}\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_dataset.map(\n",
        "    tokenize, batched=True, remove_columns=raw_dataset[\"train\"].column_names\n",
        ")\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjAcYXmtWG_p"
      },
      "source": [
        "# Initializing a new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKw56ZQKbU3",
        "outputId": "f44aec48-8ea7-477b-8b8b-997703221072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2 size: 124.2M parameters\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    \"gpt2\",\n",
        "    vocab_size=len(tokenizer),\n",
        "    n_ctx=context_length,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "model = GPT2LMHeadModel(config)\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsVuvLXGTJ4s",
        "outputId": "f88e1b11-2fc8-42e8-d717-27b992e64f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: torch.Size([5, 128])\n",
            "attention_mask shape: torch.Size([5, 128])\n",
            "labels shape: torch.Size([5, 128])\n"
          ]
        }
      ],
      "source": [
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
        "for key in out:\n",
        "    print(f\"{key} shape: {out[key].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3093835d81cc4f0d8ee4c66ef4cdea28",
            "31e12c798a4547d8890c749b13bdfb94",
            "a7af1da790cb4f9290cb5dfa5b9f8231",
            "ec64828714e84aca9450a885edb81e68",
            "d418de395f154917ab8d35921cbfc1cc",
            "850640d47953414facea11f6a63ed02f",
            "8980cafa61604dd7934969c1bb7c3b8e",
            "c94d9fbc939642f5b1dd9dc6c6681de3",
            "af79163b88c74e14bed8a2bdb5be1ceb",
            "601a077cbb5a436ba454d5cd7e0e54e6",
            "2ebece7be7a844e78b124345a3d5f428",
            "69efab0a689e4674bab974df1365ead0",
            "6e1d50e5023d4786a5d7036c2fe714d7",
            "9ac4a649dee0474cae7e6e2f0e16ae52",
            "515529e0023744698156bb49c1731663",
            "1b065469f8b740c1a97f02539c908fd1",
            "b29014d1189f4fa981bfae84e2f105e5",
            "e820fb588cde482d84a69084e2681c2e",
            "412f370f9e224843a8331b7af6b5d104",
            "1c5343eecaad4cdabba34604df2844a9",
            "6ad96f0638784687875f6c4bba8761ca",
            "bc59ed4eceff429784b1a76bd5323c8e",
            "cb78391bb91049abafba488361e5b753",
            "faac9b77c73c47c59e03de19fa0b3dc5",
            "8f0f8236338c4ce980b8ab4784b780b4",
            "4d51c8f77272463bb31f55c37f61fd0d",
            "1c487fdc744f45ee90c5f660371e33e1",
            "be0dd3172a3845a2a069f7739d10fba9",
            "65d3631eab764d0cb79b94b00037f3fe",
            "c74233f3e25d4a24a2da6caf5350625c",
            "9d2b6833926247ee8694c76411931c78",
            "5a6a374c7efa4dd2a1bfa92c768cc570"
          ]
        },
        "id": "zfoI0GaLUdSy",
        "outputId": "d65b6cc3-95e5-4112-d69e-a6651fc0bbbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3093835d81cc4f0d8ee4c66ef4cdea28"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz53xVNTUdP3"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"codehelper-ds-v2\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=5_000,\n",
        "    logging_steps=5_000,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=1_000,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=5e-2, #5e-3\n",
        "    save_steps=5_000,\n",
        "    fp16=True,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\">>>Before Train Perplexity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "GE6v-XnlFAkI",
        "outputId": "70824ad8-f54d-4ba6-c80c-fe54788eda9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2912' max='2912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2912/2912 06:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>Before Train Perplexity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.exp(eval_results['eval_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LpB5zSTOJ6J",
        "outputId": "c3f141a0-4f45-434d-f83f-643f383d6b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56957.891041258525"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM6x63HnUdM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "d7706fba-f0c9-4620-cd89-a1683d2cb74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2176' max='2176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2176/2176 1:46:03, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2176, training_loss=4014175.0588235296, metrics={'train_runtime': 6366.6513, 'train_samples_per_second': 87.521, 'train_steps_per_second': 0.342, 'total_flos': 3.6388573544448e+16, 'train_loss': 4014175.0588235296, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\">>>After Train Perplexity\")"
      ],
      "metadata": {
        "id": "cwKWjvHpFKuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "60da3a29-48e0-4b2b-cd1e-68fae9dfcda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5824' max='2912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2912/2912 1:59:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>After Train Perplexity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.exp(eval_results['eval_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R9VBzsxNQNC",
        "outputId": "b0279a27-3666-4795-f300-77a084f17375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qNk04tkTEp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "57da27ba-ad4c-4876-f4cd-0350e2932a7c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8736' max='2912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2912/2912 2:07:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': nan,\n",
              " 'eval_runtime': 397.5605,\n",
              " 'eval_samples_per_second': 234.339,\n",
              " 'eval_steps_per_second': 7.325,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaAB7LcZJfSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "083a4340-e936-4de1-a8cb-22d471015658"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'danny3/codehelper-ds-v2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub import Repository, get_full_repo_name\n",
        "api = HfApi()\n",
        "username = api.whoami()['name']\n",
        "\n",
        "MODEL_NAME = \"codehelper-ds-v2\"\n",
        "repo_name = get_full_repo_name(MODEL_NAME)\n",
        "repo_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94o4-f3Ajpyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "outputId": "bf2a40cc-dacc-43bb-a4a3-ae264be1afee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m in \u001b[92m<cell line: 2>\u001b[0m:\u001b[94m2\u001b[0m                                                                              \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m120\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m         \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m120 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m123 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mrepository.py\u001b[0m:\u001b[94m516\u001b[0m in \u001b[92m__init__\u001b[0m            \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 513 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m.huggingface_token = HfFolder.get_token()                                 \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 514 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 515 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m clone_from \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 516 \u001b[2m         \u001b[0m\u001b[96mself\u001b[0m.clone_from(repo_url=clone_from)                                          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 518 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m is_git_repo(\u001b[96mself\u001b[0m.local_dir):                                               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 519 \u001b[0m\u001b[2m            \u001b[0mlogger.debug(\u001b[33m\"\u001b[0m\u001b[33m[Repository] is a valid git repo\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m120\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m         \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m120 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m123 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mrepository.py\u001b[0m:\u001b[94m680\u001b[0m in \u001b[92mclone_from\u001b[0m          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 677 \u001b[0m\u001b[2m         \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 678 \u001b[0m\u001b[2m            \u001b[0m\u001b[2m# Check if the folder is the root of a git repository\u001b[0m                     \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_git_repo(\u001b[96mself\u001b[0m.local_dir):                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 680 \u001b[2m               \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m                  \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mTried to clone a repository in a non-empty folder that isn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt\u001b[0m\u001b[33m\"\u001b[0m    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 682 \u001b[0m\u001b[2m                  \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m a git repository (\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.local_dir\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m). If you really want to\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 683 \u001b[0m\u001b[2m                  \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m do this, do it manually:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m cd \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.local_dir\u001b[33m}\u001b[0m\u001b[33m && git init\u001b[0m\u001b[33m\"\u001b[0m    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m\n",
              "\u001b[1;91mOSError: \u001b[0mTried to clone a repository in a non-empty folder that isn't a git repository \n",
              "\u001b[1m(\u001b[0m\u001b[32m'/content/codehelper-ds-v2'\u001b[0m\u001b[1m)\u001b[0m. If you really want to do this, do it manually:\n",
              " cd \u001b[35m/content/\u001b[0m\u001b[95mcodehelper-ds-v2\u001b[0m && git init && git remote add origin && git pull origin main\n",
              " or clone repo to a new folder and move your existing files there afterwards.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">120</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> check_use_auth_token:                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118          </span>kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=ha   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119       </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>120 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">repository.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">516</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 513          </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.huggingface_token = HfFolder.get_token()                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 514       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 515       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> clone_from <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 516 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone_from(repo_url=clone_from)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 517       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 518          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_git_repo(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.local_dir):                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 519             </span>logger.debug(<span style=\"color: #808000; text-decoration-color: #808000\">\"[Repository] is a valid git repo\"</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">120</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> check_use_auth_token:                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118          </span>kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=ha   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119       </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>120 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">repository.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">680</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clone_from</span>          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 677          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 678             # Check if the folder is the root of a git repository</span>                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679             </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_git_repo(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.local_dir):                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 680 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681                   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Tried to clone a repository in a non-empty folder that isn't\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 682                   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" a git repository ('{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.local_dir<span style=\"color: #808000; text-decoration-color: #808000\">}'). If you really want to\"</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 683                   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" do this, do it manually:\\n cd {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.local_dir<span style=\"color: #808000; text-decoration-color: #808000\">} &amp;&amp; git init\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Tried to clone a repository in a non-empty folder that isn't a git repository \n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/content/codehelper-ds-v2'</span><span style=\"font-weight: bold\">)</span>. If you really want to do this, do it manually:\n",
              " cd <span style=\"color: #800080; text-decoration-color: #800080\">/content/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">codehelper-ds-v2</span> &amp;&amp; git init &amp;&amp; git remote add origin &amp;&amp; git pull origin main\n",
              " or clone repo to a new folder and move your existing files there afterwards.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "output_dir = MODEL_NAME\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repo.push_to_hub(\n",
        "#                     commit_message=\"Upload version 1 Model\", blocking=False\n",
        "#                 )"
      ],
      "metadata": {
        "id": "nM86wgmh4X1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88p8C649T4HI"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(\n",
        "    f\"{username}/{MODEL_NAME}\",\n",
        "    commit_message=\"Upload version 2 Model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r codehelper-ds.zip codehelper-ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHwrNYX3M1uB",
        "outputId": "6d4ef6b2-6177-4766-e273-506dea7bd4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: codehelper-ds/ (stored 0%)\n",
            "  adding: codehelper-ds/tokenizer.json (deflated 71%)\n",
            "  adding: codehelper-ds/generation_config.json (deflated 23%)\n",
            "  adding: codehelper-ds/.gitignore (stored 0%)\n",
            "  adding: codehelper-ds/config.json (deflated 51%)\n",
            "  adding: codehelper-ds/training_args.bin (deflated 48%)\n",
            "  adding: codehelper-ds/vocab.json (deflated 57%)\n",
            "  adding: codehelper-ds/special_tokens_map.json (deflated 60%)\n",
            "  adding: codehelper-ds/.git/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/HEAD (stored 0%)\n",
            "  adding: codehelper-ds/.git/hooks/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-push (deflated 24%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: codehelper-ds/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: codehelper-ds/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: codehelper-ds/.git/hooks/post-checkout (deflated 26%)\n",
            "  adding: codehelper-ds/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: codehelper-ds/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: codehelper-ds/.git/hooks/post-merge (deflated 25%)\n",
            "  adding: codehelper-ds/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: codehelper-ds/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: codehelper-ds/.git/hooks/post-commit (deflated 25%)\n",
            "  adding: codehelper-ds/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: codehelper-ds/.git/FETCH_HEAD (deflated 8%)\n",
            "  adding: codehelper-ds/.git/description (deflated 14%)\n",
            "  adding: codehelper-ds/.git/index (deflated 41%)\n",
            "  adding: codehelper-ds/.git/objects/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/52/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/52/721dbf29a6d99698d5de916d01b4e33d424297 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/9a/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/9a/2308bcdd411f53f702aea608b9fa481599ba45 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/86/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/86/7cc1282c570972947545e990c48f9292967bd3 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/7f/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/7f/29e620d551fc0dcc71546a2df5abd2021dc4c6 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/74/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/74/33646544cc332d7eb43c85199b5ce98e2cc0ed (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/c2/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/c2/7e9a9a0f3032072607acedba4dd45960954395 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/01/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/01/9c42e690c9e71dfbfcc4cc3b44142656a7c4bc (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/71/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/71/4ae09a6c4bcd8f5eb5e95a7a2a204c222e63c2 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/84/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/84/242bdecfcc87fc0f375b9ae103b12366cbab81 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/9c/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/9c/4d3eef7825d23e8c7edec57092cc1a7e784c3d (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/e5/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/e5/32af982c49d0868fceb6c39b7aca04a1b7e52e (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/34/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/34/4b8478e86f0cb7933a50ef1fff9127ed27266c (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/03/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/03/48ea97130c017c407fcfb6fd4003859f17b84c (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/60/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/60/66b9e4f68c05cd7ee829bb5599614bd5da4208 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/5c/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/5c/29f45fc809ee8c7cc55097ce5a2b9442bd6fd8 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/ef/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/ef/10433d99b36bf9f4f829e398669b10bd8bb5cf (deflated 0%)\n",
            "  adding: codehelper-ds/.git/objects/f3/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/f3/db007e36f7d5fcd570276da8ad4c614725a969 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/c7/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/c7/d9f3332a950355d5a77d85000f05e6f45435ea (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/4f/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/4f/064598cca06166596f249ab0fd596d10211747 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/be/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/be/9d9983502c0313e514833561e9027ddf4be2bc (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/54/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/54/6efe6d18ae2ad7758d0c9ef51cacdb81c8dc9d (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/d8/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/d8/65a41a78679a809d03734bf521fa05a530e9b3 (deflated 0%)\n",
            "  adding: codehelper-ds/.git/objects/46/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/46/23ab082d5c4816441467184a8f1e610d572e1b (deflated 0%)\n",
            "  adding: codehelper-ds/.git/objects/info/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/59/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/59/69a6bb4824adc429fd5ec312e483bab78c9f60 (stored 0%)\n",
            "  adding: codehelper-ds/.git/objects/pack/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/config (deflated 43%)\n",
            "  adding: codehelper-ds/.git/lfs/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/48/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/48/0e/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/48/0e/480eb340a18496387c5644eccfc6f62f5212f4de4eb7267fb86d8620951cce2c (deflated 62%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/e9/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/e9/da/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/e9/da/e9dace7c4f4bf8add7776178cdf43a3442855dbe622da832845a2367bd69c126 (deflated 25%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/ba/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/ba/82/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/ba/82/ba82116472c2dd1ce00e1f1f3ce6023b02531c0d84bce107ae858a08e33be19a (deflated 9%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/2a/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/2a/0d/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/2a/0d/2a0d5fcc45de0e93e67efd02cc91d47bdaed0b94fa327eafe213e39e728ff1a0 (deflated 58%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/59/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/59/07/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/lfs/objects/59/07/59078d3837c81ed76cf1071bfe34dd1efabf75f0fff01cea3b8a2e6d71ec6d01 (deflated 48%)\n",
            "  adding: codehelper-ds/.git/lfs/tmp/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/branches/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/HEAD (deflated 47%)\n",
            "  adding: codehelper-ds/.git/logs/refs/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/refs/heads/main (deflated 47%)\n",
            "  adding: codehelper-ds/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/logs/refs/remotes/origin/HEAD (deflated 23%)\n",
            "  adding: codehelper-ds/.git/logs/refs/remotes/origin/main (deflated 47%)\n",
            "  adding: codehelper-ds/.git/info/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/info/exclude (deflated 28%)\n",
            "  adding: codehelper-ds/.git/ORIG_HEAD (stored 0%)\n",
            "  adding: codehelper-ds/.git/COMMIT_EDITMSG (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/heads/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/heads/main (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/tags/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/remotes/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: codehelper-ds/.git/refs/remotes/origin/main (stored 0%)\n",
            "  adding: codehelper-ds/.git/packed-refs (deflated 10%)\n",
            "  adding: codehelper-ds/tokenizer_config.json (deflated 41%)\n",
            "  adding: codehelper-ds/pytorch_model.bin (deflated 9%)\n",
            "  adding: codehelper-ds/README.md (deflated 47%)\n",
            "  adding: codehelper-ds/runs/ (stored 0%)\n",
            "  adding: codehelper-ds/runs/May05_16-06-08_48f809ae4f74/ (stored 0%)\n",
            "  adding: codehelper-ds/runs/May05_16-06-08_48f809ae4f74/events.out.tfevents.1683309790.48f809ae4f74.9364.2 (deflated 25%)\n",
            "  adding: codehelper-ds/runs/May05_16-06-08_48f809ae4f74/events.out.tfevents.1683302778.48f809ae4f74.9364.0 (deflated 58%)\n",
            "  adding: codehelper-ds/runs/May05_16-06-08_48f809ae4f74/1683302778.358835/ (stored 0%)\n",
            "  adding: codehelper-ds/runs/May05_16-06-08_48f809ae4f74/1683302778.358835/events.out.tfevents.1683302778.48f809ae4f74.9364.1 (deflated 62%)\n",
            "  adding: codehelper-ds/.gitattributes (deflated 87%)\n",
            "  adding: codehelper-ds/merges.txt (deflated 52%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def s3_store_model(filePath: any, bytes: any, file: str) -> None:\n",
        "#     s3.put_object(\n",
        "#         Bucket=AWS_MODEL_BUCKET_NAME,\n",
        "#         Key=filePath,\n",
        "#         Body=bytes,\n",
        "#         ContentType= file.content_type\n",
        "#     )\n",
        "# path = f\"models/{MODEL_NAME}\" \n",
        "\n",
        "# s3_store_model(filePath=,bytes=,file=)"
      ],
      "metadata": {
        "id": "V5lfydxyH_Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7KIVg2TJfX9",
        "outputId": "eff77c13-0be8-4dfb-eaac-753ccc097313"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Generate text from the trained model\n",
        "# prompt = \"Hello, how are you today?\"\n",
        "prompt = \"\"\"\\\n",
        "# create some data\n",
        "x = np.random.randn(100)\n",
        "y = np.random.randn(100)\n",
        "\n",
        "# create scatter plot with x, y\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpu73S7uED0q"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# model_path = \"codehelper-ds\"\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "# generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "# output = generator(prompt, num_return_sequences=1)\n",
        "# print(output[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1CIC5j7DTLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "9a0659cf-7869-401f-a8b3-aab74d5176c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m in \u001b[92m<cell line: 2>\u001b[0m:\u001b[94m2\u001b[0m                                                                              \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtokenization_auto.py\u001b[0m:\u001b[94m657\u001b[0m in     \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m654 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# If that did not work, let's try to use the config.\u001b[0m                               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m655 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m config_tokenizer_class \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m656 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(config, PretrainedConfig):                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m657 \u001b[2m            \u001b[0mconfig = AutoConfig.from_pretrained(                                       \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m658 \u001b[0m\u001b[2m               \u001b[0mpretrained_model_name_or_path, trust_remote_code=trust_remote_code,    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m659 \u001b[0m\u001b[2m            \u001b[0m)                                                                          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m660 \u001b[0m\u001b[2m         \u001b[0mconfig_tokenizer_class = config.tokenizer_class                                \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/\u001b[0m\u001b[1;33mconfiguration_auto.py\u001b[0m:\u001b[94m916\u001b[0m in    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m913 \u001b[0m\u001b[2m      \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_from_auto\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mTrue\u001b[0m                                                        \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m914 \u001b[0m\u001b[2m      \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mname_or_path\u001b[0m\u001b[33m\"\u001b[0m] = pretrained_model_name_or_path                             \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m915 \u001b[0m\u001b[2m      \u001b[0mtrust_remote_code = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtrust_remote_code\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m)                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m916 \u001b[2m      \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m917 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mAutoConfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m]:          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m918 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m trust_remote_code:                                                      \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m919 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                          \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m573\u001b[0m in               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[92mget_config_dict\u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m570 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2m      \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                                            \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m572 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m                             \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m573 \u001b[2m      \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_name_or_path, **kwar   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m574 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m         \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m576 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m628\u001b[0m in               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[92m_get_config_dict\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m625 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m626 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m627 \u001b[0m\u001b[2m            \u001b[0m\u001b[2m# Load from local folder or from cache or download from model Hub and ca\u001b[0m   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m628 \u001b[2m            \u001b[0mresolved_config_file = cached_file(                                        \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m629 \u001b[0m\u001b[2m               \u001b[0mpretrained_model_name_or_path,                                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m630 \u001b[0m\u001b[2m               \u001b[0mconfiguration_file,                                                    \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m631 \u001b[0m\u001b[2m               \u001b[0mcache_dir=cache_dir,                                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m380\u001b[0m in \u001b[92mcached_file\u001b[0m             \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 377 \u001b[0m\u001b[2m      \u001b[0mresolved_file = os.path.join(os.path.join(path_or_repo_id, subfolder), filename)  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 378 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m os.path.isfile(resolved_file):                                             \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 379 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m _raise_exceptions_for_missing_entries:                                     \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 380 \u001b[2m            \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m               \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpath_or_repo_id\u001b[33m}\u001b[0m\u001b[33m does not appear to have a file named \u001b[0m\u001b[33m{\u001b[0mfull_filen  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 382 \u001b[0m\u001b[2m               \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/\u001b[0m\u001b[33m{\u001b[0mpath_or_repo_id\u001b[33m}\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{\u001b[0mrevision\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m for availabl\u001b[0m  \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m   \u001b[2m 383 \u001b[0m\u001b[2m            \u001b[0m)                                                                         \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m\n",
              "\u001b[1;91mOSError: \u001b[0mcodehelper-ds-v2 does not appear to have a file named config.json. Checkout \n",
              "\u001b[32m'https://huggingface.co/codehelper-ds-v2/None'\u001b[0m for available files.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">657</span> in     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">654       # If that did not work, let's try to use the config.</span>                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config_tokenizer_class <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">656          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(config, PretrainedConfig):                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>657 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>config = AutoConfig.from_pretrained(                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">658                </span>pretrained_model_name_or_path, trust_remote_code=trust_remote_code,    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">659             </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">660          </span>config_tokenizer_class = config.tokenizer_class                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">916</span> in    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">913       </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_from_auto\"</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">914       </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"name_or_path\"</span>] = pretrained_model_name_or_path                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">915       </span>trust_remote_code = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"trust_remote_code\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>916 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">917       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"AutoConfig\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span>]:          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">918          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> trust_remote_code:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">919             </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">573</span> in               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config_dict</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">570 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">571       </span>original_kwargs = copy.deepcopy(kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">572       # Get config dict associated with the base config file</span>                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>573 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_config_dict(pretrained_model_name_or_path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">574       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict:                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575          </span>original_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">576 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">628</span> in               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">625          </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">626          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">627             # Load from local folder or from cache or download from model Hub and ca</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>628 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>resolved_config_file = cached_file(                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">629                </span>pretrained_model_name_or_path,                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630                </span>configuration_file,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">631                </span>cache_dir=cache_dir,                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">380</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 377       </span>resolved_file = os.path.join(os.path.join(path_or_repo_id, subfolder), filename)  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 378       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> os.path.isfile(resolved_file):                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 379          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _raise_exceptions_for_missing_entries:                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 380 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 381                </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>path_or_repo_id<span style=\"color: #808000; text-decoration-color: #808000\">} does not appear to have a file named {</span>full_filen  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 382                </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"'https://huggingface.co/{</span>path_or_repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}/{</span>revision<span style=\"color: #808000; text-decoration-color: #808000\">}' for availabl</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 383             </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>codehelper-ds-v2 does not appear to have a file named config.json. Checkout \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/codehelper-ds-v2/None'</span> for available files.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test locally trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "prompt = '''\\\n",
        "\"\"\"create a dataframe\"\"\"\n",
        "'''\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "generated_text_ids = model.generate(input_ids=input_ids, max_length=80)\n",
        "\n",
        "generated_text = tokenizer.decode(generated_text_ids[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "pipe = pipeline(\n",
        "    \"text-generation\", model=f\"{username}/codehelper-ds\", device=device\n",
        ")"
      ],
      "metadata": {
        "id": "VTz6x924TCaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\\\n",
        "\"\"\"create some data\"\"\"\n",
        "x = np.random.randn(100)\n",
        "y = np.random.randn(100)\n",
        "\n",
        "\"\"\"function to add x and y\"\"\"\n",
        "'''\n",
        "\n",
        "print(pipe(prompt, num_return_sequences=1, max_length=100, do_sample=True)[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j106SE_1TCcw",
        "outputId": "cb085110-60d6-4b50-8ec7-a82d62b3411e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# import random forest regressor from scikit-learn\n",
            "from sklearn.ensemble import RandomForestRegressor\n",
            "\n",
            "# fit random forest model with 300 estimators on X, y:\n",
            "# X, y = digits.data, digits.target\n",
            "# x, y = np.arange(50) - 1, 0.3, 0.3, 0.7]\n",
            "\n",
            "y_test = [(X[y!= 1] | 'none')]\n",
            "\n",
            "# plot result\n",
            "c = clf.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8b0J09H4gyw"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"codeparrot/codeparrot\")\n",
        "# model = AutoModelWithLMHead.from_pretrained(\"codeparrot/codeparrot\")\n",
        "\n",
        "# inputs = tokenizer(\"def hello_world():\", return_tensors=\"pt\")\n",
        "# outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oEyQZjP11yp"
      },
      "outputs": [],
      "source": [
        "# model.config.pad_token_id = model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keytoken_ids = []\n",
        "for keyword in [\n",
        "    \"plt\",\n",
        "    \"pd\",\n",
        "    \"sk\",\n",
        "    \"fit\",\n",
        "    \"predict\",\n",
        "    \" plt\",\n",
        "    \" pd\",\n",
        "    \" sk\",\n",
        "    \" fit\",\n",
        "    \" predict\",\n",
        "    \"testtest\",\n",
        "]:\n",
        "    ids = tokenizer([keyword]).input_ids[0]\n",
        "    if len(ids) == 1:\n",
        "        keytoken_ids.append(ids[0])\n",
        "    else:\n",
        "        print(f\"Keyword has not single token: {keyword}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1qXyqORBjf1",
        "outputId": "8f164a26-9a79-4aba-f537-7c2ef77cad70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyword has not single token: testtest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "import torch\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "\n",
        "def keytoken_weighted_loss(inputs, logits, keytoken_ids, alpha=1.0):\n",
        "    # Shift so that tokens < n predict n\n",
        "    shift_labels = inputs[..., 1:].contiguous()\n",
        "    shift_logits = logits[..., :-1, :].contiguous()\n",
        "    # Calculate per-token loss\n",
        "    loss_fct = CrossEntropyLoss(reduce=False)\n",
        "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "    # Resize and average loss per sample\n",
        "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
        "    # Calculate and scale weighting\n",
        "    weights = torch.stack([(inputs == kt).float() for kt in keytoken_ids]).sum(\n",
        "        axis=[0, 2]\n",
        "    )\n",
        "    weights = alpha * (1.0 + weights)\n",
        "    # Calculate weighted average\n",
        "    weighted_loss = (loss_per_sample * weights).mean()\n",
        "    return weighted_loss\n",
        "\n",
        "\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=32, shuffle=True)\n",
        "eval_dataloader = DataLoader(tokenized_datasets[\"valid\"], batch_size=32)\n",
        "\n",
        "\n",
        "weight_decay = 0.1\n",
        "\n",
        "\n",
        "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
        "    params_with_wd, params_without_wd = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if any(nd in n for nd in no_decay):\n",
        "            params_without_wd.append(p)\n",
        "        else:\n",
        "            params_with_wd.append(p)\n",
        "    return [\n",
        "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
        "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
        "\n",
        "        losses.append(accelerator.gather(outputs.loss))\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return loss.item(), perplexity.item()"
      ],
      "metadata": {
        "id": "17VKQMLsBjjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "model = GPT2LMHeadModel(config)\n",
        "optimizer = AdamW(get_grouped_params(model), lr=5e-4)\n",
        "accelerator = Accelerator()#fp16=True)\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")\n",
        "\n",
        "num_train_epochs = 1\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=1_000,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "PDk9StzrBjlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "CQ7PBox-BjsV",
        "outputId": "9e94aedd-d59f-43b7-d089-dc291a4ec583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m in \u001b[92mevaluate\u001b[0m:\u001b[94m53\u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
              "\u001b[31m\u001b[0m\n",
              "\u001b[1;91mRuntimeError: \u001b[0mzero-dimensional tensor \u001b[1m(\u001b[0mat position \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m cannot be concatenated\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">53</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>zero-dimensional tensor <span style=\"font-weight: bold\">(</span>at position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span> cannot be concatenated\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "gradient_accumulation_steps = 8\n",
        "eval_steps = 5_000\n",
        "\n",
        "model.train()\n",
        "completed_steps = 0\n",
        "for epoch in range(num_train_epochs):\n",
        "    for step, batch in tqdm(\n",
        "        enumerate(train_dataloader, start=1), total=num_training_steps\n",
        "    ):\n",
        "        logits = model(batch[\"input_ids\"]).logits\n",
        "        loss = keytoken_weighted_loss(batch[\"input_ids\"], logits, keytoken_ids)\n",
        "        if step % 100 == 0:\n",
        "            accelerator.print(\n",
        "                {\n",
        "                    \"lr\": get_lr(),\n",
        "                    \"samples\": step * samples_per_step,\n",
        "                    \"steps\": completed_steps,\n",
        "                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
        "                }\n",
        "            )\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        accelerator.backward(loss)\n",
        "        if step % gradient_accumulation_steps == 0:\n",
        "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            completed_steps += 1\n",
        "        if (step % (eval_steps * gradient_accumulation_steps)) == 0:\n",
        "            eval_loss, perplexity = evaluate()\n",
        "            accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
        "            model.train()\n",
        "            accelerator.wait_for_everyone()\n",
        "            unwrapped_model = accelerator.unwrap_model(model)\n",
        "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "            if accelerator.is_main_process:\n",
        "                tokenizer.save_pretrained(output_dir)\n",
        "                # repo.push_to_hub(\n",
        "                #     commit_message=f\"Training in progress step {step}\", blocking=False\n",
        "                # )"
      ],
      "metadata": {
        "id": "2W5Kx-uHBjv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mT4YmM-_Bjy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POSVCLWwBj11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvX7hrcuBj5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JXpThNIjBSP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezn7sIzSKbX0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M45fy0XnmBvX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyGg3mFYmBy8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPPfYo79eHJhLP8t+qotOd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a0ec05abce5481db9803fe516232985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f07c9a2314e4b51a773e4c2e25daa1a",
              "IPY_MODEL_580ad9c52dc24f7eab779f40517cde58",
              "IPY_MODEL_7a7eb40e6c874fde810540ce36b7d7fa"
            ],
            "layout": "IPY_MODEL_0c6726f8fd824c2880ac30f2b28a3d1e"
          }
        },
        "7f07c9a2314e4b51a773e4c2e25daa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72d3567a0a3427788e47182eb57a75e",
            "placeholder": "",
            "style": "IPY_MODEL_04b5345e280b476d9417916044c86350",
            "value": "Map: 100%"
          }
        },
        "580ad9c52dc24f7eab779f40517cde58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd98bb43c00e4c949faa17b8926e9090",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_566526c82d224c65bcb74c7e935855d1",
            "value": 20000
          }
        },
        "7a7eb40e6c874fde810540ce36b7d7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32892818a224901a0cb2b3d23e5e34d",
            "placeholder": "",
            "style": "IPY_MODEL_be64231095ce4439be5c8bb91b89773a",
            "value": " 20000/20000 [03:21&lt;00:00, 99.63 examples/s]"
          }
        },
        "0c6726f8fd824c2880ac30f2b28a3d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b72d3567a0a3427788e47182eb57a75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b5345e280b476d9417916044c86350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd98bb43c00e4c949faa17b8926e9090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566526c82d224c65bcb74c7e935855d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b32892818a224901a0cb2b3d23e5e34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be64231095ce4439be5c8bb91b89773a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3163246497954064a20a04511f5e99bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68e0ee91ccf142348299c3bacc482f9d",
              "IPY_MODEL_713c9699ea3d47bd9f5061850dd4fdf7",
              "IPY_MODEL_8c38e53a1ec94e8ca1bdba3e413ca52a"
            ],
            "layout": "IPY_MODEL_75ed77403e13471cb6874cc2ec5fbd8d"
          }
        },
        "68e0ee91ccf142348299c3bacc482f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c5078b93454d7baacc1d83007a949f",
            "placeholder": "",
            "style": "IPY_MODEL_28ed4e71627341cf8c8ee4ff427ce5b6",
            "value": "Map: 100%"
          }
        },
        "713c9699ea3d47bd9f5061850dd4fdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22738db48dd42b39fc28a1c7b55e3c0",
            "max": 3322,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_899328f2c65b450088bedd770a43db05",
            "value": 3322
          }
        },
        "8c38e53a1ec94e8ca1bdba3e413ca52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c494cef61515495db5967e1e12dca9f3",
            "placeholder": "",
            "style": "IPY_MODEL_59ea99e5e6774511b209a2a73099b92c",
            "value": " 3322/3322 [00:33&lt;00:00, 100.13 examples/s]"
          }
        },
        "75ed77403e13471cb6874cc2ec5fbd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "70c5078b93454d7baacc1d83007a949f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ed4e71627341cf8c8ee4ff427ce5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a22738db48dd42b39fc28a1c7b55e3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899328f2c65b450088bedd770a43db05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c494cef61515495db5967e1e12dca9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ea99e5e6774511b209a2a73099b92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3093835d81cc4f0d8ee4c66ef4cdea28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad96f0638784687875f6c4bba8761ca",
              "IPY_MODEL_bc59ed4eceff429784b1a76bd5323c8e",
              "IPY_MODEL_cb78391bb91049abafba488361e5b753",
              "IPY_MODEL_faac9b77c73c47c59e03de19fa0b3dc5"
            ],
            "layout": "IPY_MODEL_8980cafa61604dd7934969c1bb7c3b8e"
          }
        },
        "31e12c798a4547d8890c749b13bdfb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c94d9fbc939642f5b1dd9dc6c6681de3",
            "placeholder": "",
            "style": "IPY_MODEL_af79163b88c74e14bed8a2bdb5be1ceb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a7af1da790cb4f9290cb5dfa5b9f8231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_601a077cbb5a436ba454d5cd7e0e54e6",
            "placeholder": "",
            "style": "IPY_MODEL_2ebece7be7a844e78b124345a3d5f428",
            "value": ""
          }
        },
        "ec64828714e84aca9450a885edb81e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_69efab0a689e4674bab974df1365ead0",
            "style": "IPY_MODEL_6e1d50e5023d4786a5d7036c2fe714d7",
            "value": true
          }
        },
        "d418de395f154917ab8d35921cbfc1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9ac4a649dee0474cae7e6e2f0e16ae52",
            "style": "IPY_MODEL_515529e0023744698156bb49c1731663",
            "tooltip": ""
          }
        },
        "850640d47953414facea11f6a63ed02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b065469f8b740c1a97f02539c908fd1",
            "placeholder": "",
            "style": "IPY_MODEL_b29014d1189f4fa981bfae84e2f105e5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "8980cafa61604dd7934969c1bb7c3b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c94d9fbc939642f5b1dd9dc6c6681de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af79163b88c74e14bed8a2bdb5be1ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601a077cbb5a436ba454d5cd7e0e54e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebece7be7a844e78b124345a3d5f428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69efab0a689e4674bab974df1365ead0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1d50e5023d4786a5d7036c2fe714d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ac4a649dee0474cae7e6e2f0e16ae52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515529e0023744698156bb49c1731663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "1b065469f8b740c1a97f02539c908fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29014d1189f4fa981bfae84e2f105e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e820fb588cde482d84a69084e2681c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412f370f9e224843a8331b7af6b5d104",
            "placeholder": "",
            "style": "IPY_MODEL_1c5343eecaad4cdabba34604df2844a9",
            "value": "Connecting..."
          }
        },
        "412f370f9e224843a8331b7af6b5d104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5343eecaad4cdabba34604df2844a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad96f0638784687875f6c4bba8761ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f0f8236338c4ce980b8ab4784b780b4",
            "placeholder": "",
            "style": "IPY_MODEL_4d51c8f77272463bb31f55c37f61fd0d",
            "value": "Token is valid."
          }
        },
        "bc59ed4eceff429784b1a76bd5323c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c487fdc744f45ee90c5f660371e33e1",
            "placeholder": "",
            "style": "IPY_MODEL_be0dd3172a3845a2a069f7739d10fba9",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "cb78391bb91049abafba488361e5b753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d3631eab764d0cb79b94b00037f3fe",
            "placeholder": "",
            "style": "IPY_MODEL_c74233f3e25d4a24a2da6caf5350625c",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "faac9b77c73c47c59e03de19fa0b3dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2b6833926247ee8694c76411931c78",
            "placeholder": "",
            "style": "IPY_MODEL_5a6a374c7efa4dd2a1bfa92c768cc570",
            "value": "Login successful"
          }
        },
        "8f0f8236338c4ce980b8ab4784b780b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d51c8f77272463bb31f55c37f61fd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c487fdc744f45ee90c5f660371e33e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0dd3172a3845a2a069f7739d10fba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d3631eab764d0cb79b94b00037f3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74233f3e25d4a24a2da6caf5350625c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d2b6833926247ee8694c76411931c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a6a374c7efa4dd2a1bfa92c768cc570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}