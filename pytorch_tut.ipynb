{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTQ9SUYn/BPuXsQEIhW2hy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielAdama/tutorials/blob/main/pytorch_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzB2oummz725",
        "outputId": "321ec254-0eb4-4cda-e787-394a0d5804c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tensor Basics"
      ],
      "metadata": {
        "id": "_cNFbOPa1Krc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xMtgfknv0rkB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "6w2euRxN4sIt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector\n",
        "print(x)\n",
        "x = torch.empty(2, 3) # matrix\n",
        "print(x)\n",
        "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
        "print(x)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaswRVWc1bSR",
        "outputId": "eeab3d16-ef35-4812-b4d3-244a7247a198"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.3030e-29])\n",
            "tensor([4.3081e-34, 0.0000e+00, 4.3097e-34])\n",
            "tensor([[4.3160e-34, 0.0000e+00, 4.3156e-34],\n",
            "        [0.0000e+00, 8.9683e-44, 0.0000e+00]])\n",
            "tensor([[[4.3123e-34, 0.0000e+00, 4.3124e-34],\n",
            "         [0.0000e+00, 1.1210e-43, 0.0000e+00]],\n",
            "\n",
            "        [[1.5695e-43, 0.0000e+00, 4.3123e-34],\n",
            "         [0.0000e+00, 3.3631e-44, 0.0000e+00]]])\n",
            "tensor([[0.6371, 0.6541, 0.9364],\n",
            "        [0.5821, 0.5522, 0.1427],\n",
            "        [0.9617, 0.3522, 0.3338],\n",
            "        [0.2813, 0.1654, 0.9484],\n",
            "        [0.9669, 0.5567, 0.7325]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('size',x.size())\n",
        "print('shape',x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqXJ4_WR2g9V",
        "outputId": "d27b7b1a-dcb0-4c7a-b425-36be1ccb1afd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([5, 3])\n",
            "shape torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK4AP4T24MB5",
        "outputId": "51eed054-2d8b-4158-97c1-c74a44373c25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 3).to(device) # move tensors to GPU device\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovpFD4mxjTwA",
        "outputId": "6b520f0c-e474-49b5-b86e-1fbb07b3743e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9918, 0.6505, 0.3650],\n",
            "        [0.6832, 0.4258, 0.1704],\n",
            "        [0.8502, 0.1088, 0.6541],\n",
            "        [0.0905, 0.3669, 0.8387],\n",
            "        [0.6674, 0.3863, 0.9113]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 3, device=device) # move tensors to GPU device this method is more efficient"
      ],
      "metadata": {
        "id": "-AdoNn6_jdvV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Development with Pytorch"
      ],
      "metadata": {
        "id": "sDT5uek82mPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
        "Y = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvWYQbgJjdst",
        "outputId": "86fa342a-58fc-4cb7-bf19-13fd7793d58e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test sample\n",
        "X_test = torch.tensor([[5]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "kpjOVPYvjdqT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design the Model to implement the forward pass\n",
        "\n",
        "# In pytorch, in the __init__ method we define the layers and in the forward method we apply the layers\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # Define different layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "model = LinearRegression(input_size, output_size)\n",
        "print(f\"Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13DLkkHsjdnb",
        "outputId": "2feb264a-a556-48cc-e5bc-b04084c2c889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = -1.881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(n_epochs):\n",
        "  # predict = forward pass with our model\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # Calculate the gradient\n",
        "  l.backward()\n",
        "\n",
        "  # Update the weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients after updating\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    w, b = model.parameters() # unpack parameters\n",
        "    print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
        "\n",
        "print(f\"Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcO5mTIPjdkU",
        "outputId": "fb7750e6-c0e2-4df4-b2a8-6f00509ce691"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  10 : w =  0.8462545871734619  loss =  0.15362590551376343\n",
            "epoch  20 : w =  0.8530244827270508  loss =  0.14174726605415344\n",
            "epoch  30 : w =  0.8587883114814758  loss =  0.13084836304187775\n",
            "epoch  40 : w =  0.864325761795044  loss =  0.12078744173049927\n",
            "epoch  50 : w =  0.8696460723876953  loss =  0.11150017380714417\n",
            "epoch  60 : w =  0.874757707118988  loss =  0.10292690992355347\n",
            "epoch  70 : w =  0.8796689510345459  loss =  0.09501292556524277\n",
            "epoch  80 : w =  0.8843875527381897  loss =  0.08770741522312164\n",
            "epoch  90 : w =  0.8889211416244507  loss =  0.0809636265039444\n",
            "epoch  100 : w =  0.8932769298553467  loss =  0.07473837584257126\n",
            "Prediction after training: f(5.0) = 5.066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "SS3muXqiDMf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784 # 28 x 28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=False, \n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=False)\n",
        "\n",
        "# examples = iter(test_loader)\n",
        "# example_data, example_targets = examples.next()\n",
        "\n",
        "# for i in range(6):\n",
        "#     plt.subplot(2,3,i+1)\n",
        "#     plt.imshow(example_data[i][0], cmap='gray')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "shvpAIAGjdhW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import dataloader\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass and loss calculation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "f4QHg7C9jdeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cba077-a0b5-4b20-d5e6-827435c97428"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [100/600], Loss: 0.3745\n",
            "Epoch [1/20], Step [200/600], Loss: 0.1726\n",
            "Epoch [1/20], Step [300/600], Loss: 0.2418\n",
            "Epoch [1/20], Step [400/600], Loss: 0.2344\n",
            "Epoch [1/20], Step [500/600], Loss: 0.1894\n",
            "Epoch [1/20], Step [600/600], Loss: 0.1803\n",
            "Epoch [2/20], Step [100/600], Loss: 0.1054\n",
            "Epoch [2/20], Step [200/600], Loss: 0.0834\n",
            "Epoch [2/20], Step [300/600], Loss: 0.0833\n",
            "Epoch [2/20], Step [400/600], Loss: 0.1536\n",
            "Epoch [2/20], Step [500/600], Loss: 0.0989\n",
            "Epoch [2/20], Step [600/600], Loss: 0.0987\n",
            "Epoch [3/20], Step [100/600], Loss: 0.0534\n",
            "Epoch [3/20], Step [200/600], Loss: 0.0543\n",
            "Epoch [3/20], Step [300/600], Loss: 0.0455\n",
            "Epoch [3/20], Step [400/600], Loss: 0.0807\n",
            "Epoch [3/20], Step [500/600], Loss: 0.0415\n",
            "Epoch [3/20], Step [600/600], Loss: 0.1135\n",
            "Epoch [4/20], Step [100/600], Loss: 0.0674\n",
            "Epoch [4/20], Step [200/600], Loss: 0.0370\n",
            "Epoch [4/20], Step [300/600], Loss: 0.1066\n",
            "Epoch [4/20], Step [400/600], Loss: 0.0277\n",
            "Epoch [4/20], Step [500/600], Loss: 0.0237\n",
            "Epoch [4/20], Step [600/600], Loss: 0.0171\n",
            "Epoch [5/20], Step [100/600], Loss: 0.0654\n",
            "Epoch [5/20], Step [200/600], Loss: 0.0661\n",
            "Epoch [5/20], Step [300/600], Loss: 0.0231\n",
            "Epoch [5/20], Step [400/600], Loss: 0.0467\n",
            "Epoch [5/20], Step [500/600], Loss: 0.0573\n",
            "Epoch [5/20], Step [600/600], Loss: 0.0458\n",
            "Epoch [6/20], Step [100/600], Loss: 0.0103\n",
            "Epoch [6/20], Step [200/600], Loss: 0.0107\n",
            "Epoch [6/20], Step [300/600], Loss: 0.0110\n",
            "Epoch [6/20], Step [400/600], Loss: 0.0393\n",
            "Epoch [6/20], Step [500/600], Loss: 0.0210\n",
            "Epoch [6/20], Step [600/600], Loss: 0.0117\n",
            "Epoch [7/20], Step [100/600], Loss: 0.0110\n",
            "Epoch [7/20], Step [200/600], Loss: 0.0220\n",
            "Epoch [7/20], Step [300/600], Loss: 0.0086\n",
            "Epoch [7/20], Step [400/600], Loss: 0.0234\n",
            "Epoch [7/20], Step [500/600], Loss: 0.0078\n",
            "Epoch [7/20], Step [600/600], Loss: 0.0455\n",
            "Epoch [8/20], Step [100/600], Loss: 0.0061\n",
            "Epoch [8/20], Step [200/600], Loss: 0.0373\n",
            "Epoch [8/20], Step [300/600], Loss: 0.0040\n",
            "Epoch [8/20], Step [400/600], Loss: 0.0032\n",
            "Epoch [8/20], Step [500/600], Loss: 0.0109\n",
            "Epoch [8/20], Step [600/600], Loss: 0.0141\n",
            "Epoch [9/20], Step [100/600], Loss: 0.0114\n",
            "Epoch [9/20], Step [200/600], Loss: 0.0078\n",
            "Epoch [9/20], Step [300/600], Loss: 0.0171\n",
            "Epoch [9/20], Step [400/600], Loss: 0.0120\n",
            "Epoch [9/20], Step [500/600], Loss: 0.0095\n",
            "Epoch [9/20], Step [600/600], Loss: 0.0058\n",
            "Epoch [10/20], Step [100/600], Loss: 0.0218\n",
            "Epoch [10/20], Step [200/600], Loss: 0.0073\n",
            "Epoch [10/20], Step [300/600], Loss: 0.0133\n",
            "Epoch [10/20], Step [400/600], Loss: 0.0055\n",
            "Epoch [10/20], Step [500/600], Loss: 0.0385\n",
            "Epoch [10/20], Step [600/600], Loss: 0.0028\n",
            "Epoch [11/20], Step [100/600], Loss: 0.0165\n",
            "Epoch [11/20], Step [200/600], Loss: 0.0025\n",
            "Epoch [11/20], Step [300/600], Loss: 0.0189\n",
            "Epoch [11/20], Step [400/600], Loss: 0.0044\n",
            "Epoch [11/20], Step [500/600], Loss: 0.0025\n",
            "Epoch [11/20], Step [600/600], Loss: 0.0016\n",
            "Epoch [12/20], Step [100/600], Loss: 0.0149\n",
            "Epoch [12/20], Step [200/600], Loss: 0.0010\n",
            "Epoch [12/20], Step [300/600], Loss: 0.0024\n",
            "Epoch [12/20], Step [400/600], Loss: 0.0046\n",
            "Epoch [12/20], Step [500/600], Loss: 0.0022\n",
            "Epoch [12/20], Step [600/600], Loss: 0.0026\n",
            "Epoch [13/20], Step [100/600], Loss: 0.0043\n",
            "Epoch [13/20], Step [200/600], Loss: 0.0067\n",
            "Epoch [13/20], Step [300/600], Loss: 0.0007\n",
            "Epoch [13/20], Step [400/600], Loss: 0.0019\n",
            "Epoch [13/20], Step [500/600], Loss: 0.0031\n",
            "Epoch [13/20], Step [600/600], Loss: 0.0040\n",
            "Epoch [14/20], Step [100/600], Loss: 0.0007\n",
            "Epoch [14/20], Step [200/600], Loss: 0.0037\n",
            "Epoch [14/20], Step [300/600], Loss: 0.0086\n",
            "Epoch [14/20], Step [400/600], Loss: 0.0010\n",
            "Epoch [14/20], Step [500/600], Loss: 0.0007\n",
            "Epoch [14/20], Step [600/600], Loss: 0.0078\n",
            "Epoch [15/20], Step [100/600], Loss: 0.0211\n",
            "Epoch [15/20], Step [200/600], Loss: 0.0048\n",
            "Epoch [15/20], Step [300/600], Loss: 0.0039\n",
            "Epoch [15/20], Step [400/600], Loss: 0.0012\n",
            "Epoch [15/20], Step [500/600], Loss: 0.0019\n",
            "Epoch [15/20], Step [600/600], Loss: 0.0084\n",
            "Epoch [16/20], Step [100/600], Loss: 0.0072\n",
            "Epoch [16/20], Step [200/600], Loss: 0.0027\n",
            "Epoch [16/20], Step [300/600], Loss: 0.0028\n",
            "Epoch [16/20], Step [400/600], Loss: 0.0009\n",
            "Epoch [16/20], Step [500/600], Loss: 0.0110\n",
            "Epoch [16/20], Step [600/600], Loss: 0.0004\n",
            "Epoch [17/20], Step [100/600], Loss: 0.0007\n",
            "Epoch [17/20], Step [200/600], Loss: 0.0119\n",
            "Epoch [17/20], Step [300/600], Loss: 0.0002\n",
            "Epoch [17/20], Step [400/600], Loss: 0.0024\n",
            "Epoch [17/20], Step [500/600], Loss: 0.0223\n",
            "Epoch [17/20], Step [600/600], Loss: 0.0022\n",
            "Epoch [18/20], Step [100/600], Loss: 0.0014\n",
            "Epoch [18/20], Step [200/600], Loss: 0.0015\n",
            "Epoch [18/20], Step [300/600], Loss: 0.0004\n",
            "Epoch [18/20], Step [400/600], Loss: 0.0017\n",
            "Epoch [18/20], Step [500/600], Loss: 0.0004\n",
            "Epoch [18/20], Step [600/600], Loss: 0.0014\n",
            "Epoch [19/20], Step [100/600], Loss: 0.0036\n",
            "Epoch [19/20], Step [200/600], Loss: 0.0005\n",
            "Epoch [19/20], Step [300/600], Loss: 0.0006\n",
            "Epoch [19/20], Step [400/600], Loss: 0.0279\n",
            "Epoch [19/20], Step [500/600], Loss: 0.0093\n",
            "Epoch [19/20], Step [600/600], Loss: 0.0080\n",
            "Epoch [20/20], Step [100/600], Loss: 0.0022\n",
            "Epoch [20/20], Step [200/600], Loss: 0.0021\n",
            "Epoch [20/20], Step [300/600], Loss: 0.0003\n",
            "Epoch [20/20], Step [400/600], Loss: 0.0003\n",
            "Epoch [20/20], Step [500/600], Loss: 0.0004\n",
            "Epoch [20/20], Step [600/600], Loss: 0.0079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model: we don't need to compute gradients\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (output_value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPj87UaSKcsk",
        "outputId": "4933d7da-2a00-4db8-e4ca-2df5ebf28407"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.09 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. CNN\n",
        "\n",
        "This section covers:\n",
        "\n",
        "- Convolutional Layers\n",
        "- MaxPooling\n",
        "- Save/Load model"
      ],
      "metadata": {
        "id": "JIbbWBJqTI59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(imgs):\n",
        "    imgs = imgs / 2 + 0.5   # unnormalize\n",
        "    npimgs = imgs.numpy()\n",
        "    plt.imshow(np.transpose(npimgs, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# one batch of random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "# img_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\n",
        "# imshow(img_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QawVHYVKcoD",
        "outputId": "5f262a4d-93b5-4777-8830-768c9b0d81a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(64*4*4, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # N, 3, 32, 32\n",
        "        x = F.relu(self.conv1(x))   # -> N, 32, 30, 30\n",
        "        x = self.pool(x)            # -> N, 32, 15, 15\n",
        "        x = F.relu(self.conv2(x))   # -> N, 64, 13, 13\n",
        "        x = self.pool(x)            # -> N, 64, 6, 6\n",
        "        x = F.relu(self.conv3(x))   # -> N, 64, 4, 4\n",
        "        x = torch.flatten(x, 1)     # -> N, 1024\n",
        "        x = F.relu(self.fc1(x))     # -> N, 64\n",
        "        x = self.fc2(x)             # -> N, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "396Je9-sKclf",
        "outputId": "c46608c4-590f-47c2-b1ae-40819a4f0bfc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.469\n",
            "[2] loss: 1.091\n",
            "[3] loss: 0.928\n",
            "[4] loss: 0.821\n",
            "[5] loss: 0.747\n",
            "[6] loss: 0.689\n",
            "[7] loss: 0.646\n",
            "[8] loss: 0.605\n",
            "[9] loss: 0.564\n",
            "[10] loss: 0.530\n",
            "[11] loss: 0.497\n",
            "[12] loss: 0.469\n",
            "[13] loss: 0.439\n",
            "[14] loss: 0.411\n",
            "[15] loss: 0.384\n",
            "[16] loss: 0.367\n",
            "[17] loss: 0.341\n",
            "[18] loss: 0.322\n",
            "[19] loss: 0.304\n",
            "[20] loss: 0.281\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = ConvNet()\n",
        "loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_correct2 = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        outputs2 = loaded_model(images)\n",
        "        _, predicted2 = torch.max(outputs2, 1)\n",
        "        n_correct2 += (predicted2 == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the model: {acc} %')\n",
        "\n",
        "    acc = 100.0 * n_correct2 / n_samples\n",
        "    print(f'Accuracy of the loaded model: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_T_8cy3Kcg1",
        "outputId": "ecaf87a7-85d9-4f72-8fce-5cdf384fd881"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 71.39 %\n",
            "Accuracy of the loaded model: 71.39 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cL9aPmklKccO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0paINpSKcY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-lMXfArKcVW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}